# -*- coding: utf-8 -*-
"""DL_Minor1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/147jak1R9-MxvL06C1ziAyOBcXujDLLfi

## ***Question 1***
"""

import numpy as np 
import torch
import torch.nn.functional as F
from torchvision import datasets,transforms
from torch import nn
import matplotlib.pyplot as plt
from PIL import Image
import numpy as np
import seaborn as sns
import torchvision.transforms.functional as aug

train=datasets.CIFAR10('./root',train=True,download=True,transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((.5,.5,.5),(.5,.5,.5))]))
test=datasets.CIFAR10('./root',train=False,download=True,transform=transforms.Compose([transforms.ToTensor(),transforms.Normalize((.5,.5,.5),(.5,.5,.5))]))

torch.cuda.is_available()   # Checking if GPU is available

train1=[]
test1=[]
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')   # Using GPU for faster calculations
for x,y in train:
  x=x.to(device)
  train1.append((x,y))

for x,y in test:
  x=x.to(device)
  test1.append((x,y))

train1[0][0].is_cuda         # Checking if tensors are in CPU or GPU

print(len(train1))
print(len(test1))

training=[]
testing=[]
for x,y in train1:                       # Since DD+MM+YY = 118 which is even
  if y in (0,2,4,6,8):                  # Choosing only 0,2,4,6,8 target labels
    training.append((x,y//2))            # Dividing by 2 to get 5 nos of classes

print(len(training))                     # Length of training and test reduced to half

subset1, subset2,subset3 = torch.utils.data.random_split(training, [5000, 5000,15000])
# Creating subsets to apply data augmentation

for x,y in subset1:                     # images rotating by 10 degress.
  r=aug.rotate(x,10)
  training.append((r,y))

print(len(training))                    # Added 5000 rotated images to our train set

img=torch.randn(x.size())
transform = transforms.ToPILImage()            # Gaussian noise
img1 = transform(img)
display(img1)

for x,y in subset2:                                   
  gauss_img=x + torch.randn(x.size()).to(device)         # Adding gaussian noise to 5000 images
  training.append((gauss_img,y))

len(training)

for x,y in test:
  if y in (0,2,4,6,8):
    testing.append((x,y//2))

len(testing)

from torch.utils.data import random_split
training, val = random_split(training, [30000, 5000])                   # Splitting in test and validation set

display(transform(training[0][0]))

trainset = torch.utils.data.DataLoader(training, 64, shuffle=True)
valset = torch.utils.data.DataLoader(val, 64, shuffle=False)          # Batch size as 64 
testset = torch.utils.data.DataLoader(testing, 64, shuffle=False)

class CNN(nn.Module):
    def __init__(self):
        super(CNN, self).__init__()
        self.conv1 = nn.Conv2d(in_channels=3, out_channels=12, kernel_size=3, stride=1, padding=2)  # 12 Filters in 1st Layer
        nn.init.kaiming_uniform_(self.conv1.weight, mode='fan_in', nonlinearity='relu').to(device)     # Using He weights initialization
        self.conv2 = nn.Conv2d(in_channels=12, out_channels=24, kernel_size=3, stride=1, padding=2)
        nn.init.kaiming_uniform_(self.conv2.weight, mode='fan_in', nonlinearity='relu').to(device)     # Since image is RGB , so in_channel size is 3
        self.conv3 = nn.Conv2d(in_channels=24, out_channels=48, kernel_size=3, stride=1, padding=2)
        nn.init.kaiming_uniform_(self.conv3.weight, mode='fan_in', nonlinearity='relu').to(device)
        self.conv4 = nn.Conv2d(in_channels=48, out_channels=96, kernel_size=3, stride=1, padding=2)
        nn.init.kaiming_uniform_(self.conv4.weight, mode='fan_in', nonlinearity='relu').to(device)
        self.conv5 = nn.Conv2d(in_channels=96, out_channels=192, kernel_size=3, stride=1, padding=2)
        nn.init.kaiming_uniform_(self.conv5.weight, mode='fan_in', nonlinearity='relu').to(device)
        self.conv6 = nn.Conv2d(in_channels=192, out_channels=384, kernel_size=3, stride=1, padding=2)
        nn.init.kaiming_uniform_(self.conv6.weight, mode='fan_in', nonlinearity='relu').to(device)
        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)                       # Max pooling as MM is odd
        self.fc1 = nn.Linear(384, 1024)
        nn.init.kaiming_uniform_(self.fc1.weight, mode='fan_in', nonlinearity='relu').to(device)
        self.fc2 = nn.Linear(1024, 5)                                       # Output having 5 neurons 
    def forward(self, x):
         x = self.pool(F.relu(self.conv1(x)))
         # print(x.shape)
         x = self.pool(F.relu(self.conv2(x)))
         x = self.pool(F.relu(self.conv3(x)))
         # print(x.shape)
         x = self.pool(F.relu(self.conv4(x)))
         x = self.pool(F.relu(self.conv5(x)))
         # print(x.shape)
         x = self.pool(F.relu(self.conv6(x)))
         x = self.pool(x)
         # print(x.shape)
         x = x.view(-1, 384)
         x = F.relu(self.fc1(x))
         # print(x.shape)
         x = self.fc2(x)
         return F.log_softmax(x, dim=1)

net = CNN()
print(net)
import torch.optim as optim
optimizer = optim.Adam(net.parameters(), lr=0.001)
loss = nn.CrossEntropyLoss()

valid_losslist=[]
train_losslist = []
valid_loss_min = np.Inf                        # Initialize valid loss to high value 
for epoch in range(1, 9):
    train_loss = 0.0
    valid_loss = 0.0
    for data, target in trainset:
        optimizer.zero_grad()                           # clear the gradients of all optimized variables 
        output = net(data)                             
        losses = loss(output, target)                     # calculate the batch loss
        losses.backward()
        optimizer.step()
        train_loss += losses.item()*data.size(0)         # update training loss
     
    for data, target in valset:
        output = net(data)
        losses = loss(output, target)
        valid_loss += losses.item()*data.size(0)
    
    train_loss = train_loss/len(trainset.dataset)
    valid_loss = valid_loss/len(valset.dataset)
    train_losslist.append(train_loss)
    valid_losslist.append(valid_loss)
        
    print('Epoch: {} \tTraining Loss: {:.6f} \tValidation Loss: {:.6f}'.format(epoch, train_loss, valid_loss))
    
    if valid_loss <= valid_loss_min:
        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))
        torch.save(net.state_dict(), 'model_cifar.pt')
        valid_loss_min = valid_loss

plt.plot(range(1,9),valid_losslist,'b',marker='o')
plt.plot(range(1,9), train_losslist,'r',marker='o')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(["validation loss", "Training loss"], loc ="lower left")
plt.show()

correct=0
model = CNN()
model.load_state_dict(torch.load("model_cifar.pt"))    # Loading the saved model 
model.eval()
with torch.no_grad():
    for data in testset:
        X, y = data
        output = net(X)                           # Accuracy on test set
        for idx, i in enumerate(output):
            if torch.argmax(i) == y[idx]:
                correct = correct + 1
print("Accuracy: ", round(correct/5000, 3))

"""## ***Question 2***"""

class Autoencoder(nn.Module):
    def __init__(self):
        super(Autoencoder, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(3072, 1024),              # Input features equals to number of pixels i.e. 3072
            nn.ReLU(),
            nn.Linear(1024, 256),
            nn.ReLU(),                          # Since ABC is 011 which is odd so 3 layers chosen
            nn.Linear(256, 64),
            nn.ReLU())
        self.decoder = nn.Sequential(
            nn.Linear(64, 256),
            nn.ReLU(),
            nn.Linear(256, 1024),
            nn.ReLU(),
            nn.Linear(1024, 3072),
            nn.Tanh())                             # Tanh activation at output as images are normalized between -1,1

    def forward(self, x):
        x = self.encoder(x)
        x = self.decoder(x)
        return x

autoencoder = Autoencoder()
optimizer = torch.optim.Adam(autoencoder.parameters(), lr=0.001)
loss_fn = F.mse_loss

for epoch in range(3):
    for i, (images, _) in enumerate(trainset):

        images = images.view(images.size(0), -1)

        optimizer.zero_grad()
        output = autoencoder(images)

        loss = loss_fn(output, images)
        loss.backward()
        optimizer.step()

torch.save(autoencoder.state_dict(), "autoencoder.pth")     # Saving the model

model = Autoencoder()                                       # Loading just the encoder part
model.load_state_dict(torch.load("autoencoder.pth"))
encoder = autoencoder.encoder

class AutoencoderWithFC(nn.Module):
    def __init__(self, encoder):
        super(AutoencoderWithFC, self).__init__()
        self.encoder = encoder
        self.fc1 = nn.Linear(64,256)
        self.fc2 = nn.Linear(256,5)                # Since, MM is odd so 256 nodes
    def forward(self, x):
        x = self.encoder(x)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return F.log_softmax(x,dim=1)

model=AutoencoderWithFC(encoder)
import torch.optim as optim
optimizer=optim.Adam(model.parameters(), lr=0.001)
loss = nn.CrossEntropyLoss()

valid_losslist=[]
train_losslist = []
valid_loss_min = np.Inf                        # Initialize valid loss to high value
for epoch in range(1, 9):
    train_loss = 0.0
    valid_loss = 0.0
    for data, target in trainset:
        data = data.view(data.size(0), -1)
        optimizer.zero_grad()                          
        output = model(data)                             
        losses = loss(output, target)                     # calculate the batch loss
        losses.backward()
        optimizer.step()
        train_loss += losses.item()*data.size(0)         # update training loss
     
    for data, target in valset:
        data = data.view(data.size(0), -1)
        output = model(data)
        losses = loss(output, target)
        valid_loss += losses.item()*data.size(0)
    
    train_loss = train_loss/len(trainset.dataset)
    valid_loss = valid_loss/len(valset.dataset)
    train_losslist.append(train_loss)
    valid_losslist.append(valid_loss)
        
    print('Epoch: {} \tTraining Loss: {:.6f} \tValidation Loss: {:.6f}'.format(epoch, train_loss, valid_loss))
    

    if valid_loss <= valid_loss_min:
        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))
        torch.save(model.state_dict(), 'autoencoder_cifar.pt')
        valid_loss_min = valid_loss

plt.plot(range(1,9),valid_losslist,'b',marker='o')
plt.plot(range(1,9), train_losslist,'r',marker='o')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend(["validation loss", "Training loss"], loc ="lower left")
plt.show()

correct=0
model = model=AutoencoderWithFC(encoder)
model.load_state_dict(torch.load("autoencoder_cifar.pt"))
model.eval()
with torch.no_grad():
    for data in testset:
        X, y = data
        X = X.view(X.size(0), -1)
        output = model(X)                           # Accuracy on test set
        for idx, i in enumerate(output):
            if torch.argmax(i) == y[idx]:
                correct = correct + 1
print("Accuracy: ", round(correct/5000, 3))

